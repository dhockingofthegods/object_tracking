{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8543123,"sourceType":"datasetVersion","datasetId":5104015},{"sourceId":8543548,"sourceType":"datasetVersion","datasetId":5104332},{"sourceId":8543614,"sourceType":"datasetVersion","datasetId":5104380},{"sourceId":8543804,"sourceType":"datasetVersion","datasetId":5104522},{"sourceId":8546312,"sourceType":"datasetVersion","datasetId":5106234},{"sourceId":8566017,"sourceType":"datasetVersion","datasetId":5121093}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/wjnwjn59/deep_sort.git","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:52:06.960687Z","iopub.execute_input":"2024-05-31T02:52:06.961342Z","iopub.status.idle":"2024-05-31T02:52:08.523228Z","shell.execute_reply.started":"2024-05-31T02:52:06.961306Z","shell.execute_reply":"2024-05-31T02:52:08.521975Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'deep_sort'...\nremote: Enumerating objects: 167, done.\u001b[K\nremote: Counting objects: 100% (25/25), done.\u001b[K\nremote: Compressing objects: 100% (18/18), done.\u001b[K\nremote: Total 167 (delta 9), reused 15 (delta 7), pack-reused 142\u001b[K\nReceiving objects: 100% (167/167), 77.68 KiB | 1.73 MiB/s, done.\nResolving deltas: 100% (92/92), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown==4.6.0 -q\n!gdown --no-check-certificate --folder https://drive.google.com/open?id=18fKzfqnqhqW3s9zwsCbnVJ5XF2JFeqMp\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T02:52:08.525735Z","iopub.execute_input":"2024-05-31T02:52:08.526671Z","iopub.status.idle":"2024-05-31T02:53:49.697263Z","shell.execute_reply.started":"2024-05-31T02:52:08.526619Z","shell.execute_reply":"2024-05-31T02:53:49.696302Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Retrieving folder list\nRetrieving folder 1VVqtL0klSUvLnmBKS89il1EKC3IxUBVK detections\nRetrieving folder 1qNWOpUtKG8GqEiL-LbBdXyvifUtcbOvc MOT16_POI_test\nProcessing file 1aEzvFHPK-N6hqLXMqhh3i9JJzn7WFUA3 MOT16-01.npy\nProcessing file 1h_ktJDBIEXaSBAA-RxKNYnL9e4fp2HPd MOT16-03.npy\nProcessing file 1ilOElwfYZLwQKH57HoYdXfuYhpPibfqF MOT16-06.npy\nProcessing file 1TajzH3GbumKmtYvKBvOtGERFGD0tStwG MOT16-07.npy\nProcessing file 1WB9Mi4RLVPHV4_20sVq7FdoeG5JYQ_J1 MOT16-08.npy\nProcessing file 1mksH9GWNT7zmcuq6rlRev8pevZz8Rfsm MOT16-12.npy\nProcessing file 1FVVhn_IpxQ_jkYhc0CUQHSQMm1SMTEBj MOT16-14.npy\nRetrieving folder 1DcOcApOkxP3NdeIUXxVF1KNex6T6YDq3 MOT16_POI_train\nProcessing file 1Va__9NWU2ZCmaxIq4oIabi05NYWEOk1K MOT16-02.npy\nProcessing file 1EH7orgDPp7kqRY5OA0hEctcEtQnYq0Ea MOT16-04.npy\nProcessing file 1RCfHJx5ZoUecapbZCsgp0tCEiItvLsd8 MOT16-05.npy\nProcessing file 1VLOvn-mbpY0Q1rsMONQZhaEQIGEmyLQL MOT16-09.npy\nProcessing file 1SbMhOgYPvZ84xE8lRtXc7CLXJF86lwf4 MOT16-10.npy\nProcessing file 1a4w-HopWJHLFVi4e5wM_CEpv_ZgAVSys MOT16-11.npy\nProcessing file 1EOOPm2-09roynRlIxUCRSxBhChY8PA9D MOT16-13.npy\nRetrieving folder 1m2ebLHB2JThZC8vWGDYEKGsevLssSkjo networks\nProcessing file 1hF6Cehn1SNZvh-M7FItSjEFojf_MVUba mars-small128.ckpt-68577\nProcessing file 1FkpWjshRY1YZC3dtQT9DNUbVZLu97uqi mars-small128.ckpt-68577.meta\nProcessing file 1bB66hP9voDXuoBoaCcKYY7a8IYzMMs4P mars-small128.pb\nRetrieving folder list completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1aEzvFHPK-N6hqLXMqhh3i9JJzn7WFUA3\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-01.npy\n100%|██████████████████████████████████████| 11.3M/11.3M [00:00<00:00, 79.6MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1h_ktJDBIEXaSBAA-RxKNYnL9e4fp2HPd\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-03.npy\n100%|████████████████████████████████████████| 106M/106M [00:01<00:00, 83.4MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1ilOElwfYZLwQKH57HoYdXfuYhpPibfqF\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-06.npy\n100%|██████████████████████████████████████| 12.0M/12.0M [00:00<00:00, 27.5MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1TajzH3GbumKmtYvKBvOtGERFGD0tStwG\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-07.npy\n100%|██████████████████████████████████████| 17.7M/17.7M [00:00<00:00, 53.8MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1WB9Mi4RLVPHV4_20sVq7FdoeG5JYQ_J1\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-08.npy\n100%|███████████████████████████████████████| 16.0M/16.0M [00:00<00:00, 143MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1mksH9GWNT7zmcuq6rlRev8pevZz8Rfsm\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-12.npy\n100%|██████████████████████████████████████| 8.92M/8.92M [00:00<00:00, 51.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1FVVhn_IpxQ_jkYhc0CUQHSQMm1SMTEBj\nTo: /kaggle/working/resources/detections/MOT16_POI_test/MOT16-14.npy\n100%|██████████████████████████████████████| 21.1M/21.1M [00:00<00:00, 68.1MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Va__9NWU2ZCmaxIq4oIabi05NYWEOk1K\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-02.npy\n100%|██████████████████████████████████████| 15.6M/15.6M [00:00<00:00, 63.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1EH7orgDPp7kqRY5OA0hEctcEtQnYq0Ea\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-04.npy\n100%|███████████████████████████████████████| 44.9M/44.9M [00:00<00:00, 121MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1RCfHJx5ZoUecapbZCsgp0tCEiItvLsd8\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-05.npy\n100%|██████████████████████████████████████| 5.65M/5.65M [00:00<00:00, 29.9MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1VLOvn-mbpY0Q1rsMONQZhaEQIGEmyLQL\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-09.npy\n100%|██████████████████████████████████████| 4.66M/4.66M [00:00<00:00, 24.1MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1SbMhOgYPvZ84xE8lRtXc7CLXJF86lwf4\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-10.npy\n100%|██████████████████████████████████████| 14.6M/14.6M [00:00<00:00, 42.8MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1a4w-HopWJHLFVi4e5wM_CEpv_ZgAVSys\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-11.npy\n100%|██████████████████████████████████████| 9.27M/9.27M [00:00<00:00, 21.7MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1EOOPm2-09roynRlIxUCRSxBhChY8PA9D\nTo: /kaggle/working/resources/detections/MOT16_POI_train/MOT16-13.npy\n100%|██████████████████████████████████████| 15.3M/15.3M [00:00<00:00, 71.4MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1hF6Cehn1SNZvh-M7FItSjEFojf_MVUba\nTo: /kaggle/working/resources/networks/mars-small128.ckpt-68577\n100%|███████████████████████████████████████| 36.0M/36.0M [00:00<00:00, 106MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1FkpWjshRY1YZC3dtQT9DNUbVZLu97uqi\nTo: /kaggle/working/resources/networks/mars-small128.ckpt-68577.meta\n100%|███████████████████████████████████████| 1.35M/1.35M [00:00<00:00, 127MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1bB66hP9voDXuoBoaCcKYY7a8IYzMMs4P\nTo: /kaggle/working/resources/networks/mars-small128.pb\n100%|██████████████████████████████████████| 11.2M/11.2M [00:00<00:00, 68.5MB/s]\nDownload completed\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:53:49.698717Z","iopub.execute_input":"2024-05-31T02:53:49.699027Z","iopub.status.idle":"2024-05-31T02:53:49.925362Z","shell.execute_reply.started":"2024-05-31T02:53:49.698998Z","shell.execute_reply":"2024-05-31T02:53:49.924641Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics -q\nimport ultralytics\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:53:49.927923Z","iopub.execute_input":"2024-05-31T02:53:49.928564Z","iopub.status.idle":"2024-05-31T02:54:10.189671Z","shell.execute_reply.started":"2024-05-31T02:53:49.928527Z","shell.execute_reply":"2024-05-31T02:54:10.188717Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.26 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5643.4/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\nclass YOLOv8:\n    def __init__(\n        self ,\n        model_path\n        ):\n        self.model =YOLO(model_path)\n    def detect(self,source_img ):\n        results = self.model.predict(source_img,verbose = False )[0]\n        bboxes = results.boxes.xywh.cpu().numpy()\n        bboxes[:,:2] = bboxes[:,:2] - (bboxes[:,2:]/2)\n        scores = results.boxes.conf.cpu().numpy()\n        class_ids = results.boxes.cls.cpu().numpy()\n        return bboxes , scores , class_ids\n        \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:10.191029Z","iopub.execute_input":"2024-05-31T02:54:10.191459Z","iopub.status.idle":"2024-05-31T02:54:10.198652Z","shell.execute_reply.started":"2024-05-31T02:54:10.191431Z","shell.execute_reply":"2024-05-31T02:54:10.197635Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from deep_sort.deep_sort import nn_matching\nfrom deep_sort.deep_sort.detection import Detection\nfrom deep_sort.deep_sort.tracker import Tracker\nfrom deep_sort.tools import generate_detections as gdet","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:10.200019Z","iopub.execute_input":"2024-05-31T02:54:10.200350Z","iopub.status.idle":"2024-05-31T02:54:23.172227Z","shell.execute_reply.started":"2024-05-31T02:54:10.200326Z","shell.execute_reply":"2024-05-31T02:54:23.171438Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DeepSORT :\n    def __init__ (\n        self,\n        model_path = '/kaggle/working/resources/networks/mars-small128.pb',\n        max_cosine_distance = 0.7,\n        nn_budget = None,\n        classes = ['human']\n    ):\n        self.encoder =gdet.create_box_encoder(model_path,batch_size =1)\n        self.metric =nn_matching.NearestNeighborDistanceMetric('cosine',max_cosine_distance,nn_budget)\n        self.tracker =Tracker(self.metric)\n        key_list = []\n        val_list = []\n        for ID, class_name in enumerate(classes):\n            key_list.append(ID)\n            val_list.append(class_name)\n        self.key_list = key_list\n        self.val_list = val_list\n        \n    def tracking(self, origin_frame, bboxes,scores,class_ids):\n        features = self.encoder(origin_frame,bboxes)\n        \n        detections = [Detection(bbox,score,class_id,feature)\n                     for bbox,score,class_id,feature in zip(bboxes,\n                                                           scores,\n                                                           class_ids,\n                                                            features)]\n        self.tracker.predict()\n        self.tracker.update(detections)\n        \n        tracked_bboxes = []\n        for track in self.tracker.tracks:\n            if not track.is_confirmed() or track.time_since_update >5:\n                continue\n            bbox = track.to_tlbr\n            class_id = track.get_class()\n            conf_score = track.get_conf_score()\n            tracking_id = track.track_id\n            tracked_bboxes.append(\n                bbox.tolist() + [class_id, conf_score,tracking_id]\n            )\n            \n        tracked_bboxes = np.array(tracked_bboxes)\n        \n        return tracked_bboxes\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:23.173435Z","iopub.execute_input":"2024-05-31T02:54:23.174006Z","iopub.status.idle":"2024-05-31T02:54:23.184943Z","shell.execute_reply.started":"2024-05-31T02:54:23.173979Z","shell.execute_reply":"2024-05-31T02:54:23.183913Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DeepSORT:\n    def __init__(\n        self,\n        model_path='/kaggle/working/resources/networks/mars-small128.pb',\n        max_cosine_distance = 0.7,\n        nn_budget = None,\n        classes=['human']\n    ):\n\n        self.encoder = gdet.create_box_encoder(model_path, batch_size=1)\n        self.metric = nn_matching.NearestNeighborDistanceMetric('cosine', max_cosine_distance, nn_budget)\n        self.tracker = Tracker(self.metric)\n\n        key_list = []\n        val_list = []\n        for ID, class_name in enumerate(classes):\n            key_list.append(ID)\n            val_list.append(class_name)\n        self.key_list = key_list\n        self.val_list = val_list\n\n    def tracking(\n        self,\n        origin_frame,\n        bboxes,\n        scores,\n        class_ids\n    ):\n        features = self.encoder(origin_frame, bboxes)\n\n        detections = [Detection(bbox, score, class_id, feature)\n            for bbox, score, class_id, feature in zip(bboxes, scores, class_ids, features)]\n\n        self.tracker.predict()\n        self.tracker.update(detections)\n\n        tracked_bboxes = []\n        for track in self.tracker.tracks:\n            if not track.is_confirmed() or track.time_since_update > 5:\n                continue\n            bbox = track.to_tlbr()\n            class_id = track.get_class()\n            conf_score = track.get_conf_score()\n            tracking_id = track.track_id\n            tracked_bboxes.append(\n                bbox.tolist() + [class_id, conf_score, tracking_id]\n            )\n\n        tracked_bboxes = np.array(tracked_bboxes)\n\n        return tracked_bboxes","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:23.186181Z","iopub.execute_input":"2024-05-31T02:54:23.186517Z","iopub.status.idle":"2024-05-31T02:54:23.255688Z","shell.execute_reply.started":"2024-05-31T02:54:23.186485Z","shell.execute_reply":"2024-05-31T02:54:23.254749Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def draw_detection(\n    img,\n    bboxes,\n    scores,\n    class_ids,\n    ids,\n    classes=['human'],\n    mask_alpha=0.3\n):\n    height, width = img.shape[:2]\n    np.random.seed(0)\n    rng = np.random.default_rng(3)\n    colors = rng.uniform(0, 255, size=(len(classes), 3))\n\n    mask_img = img.copy()\n    det_img = img.copy()\n\n    size = min([height, width]) * 0.0006\n    text_thickness = int(min([height, width]) * 0.001)\n\n    # Draw bounding boxes and labels of detections\n    for bbox, score, class_id, id_ in zip(bboxes, scores, class_ids, ids):\n        color = colors[class_id]\n\n        x1, y1, x2, y2 = bbox.astype(int)\n\n        # Draw rectangle\n        cv2.rectangle(det_img, (x1, y1), (x2, y2), color, 2)\n\n        # Draw fill rectangle in mask image\n        cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, -1)\n\n        label = classes[class_id]\n        caption = f'{label} {int(score * 100)}% ID: {id_}'\n        (tw, th), _ = cv2.getTextSize(text=caption, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                                    fontScale=size, thickness=text_thickness)\n        th = int(th * 1.2)\n\n        cv2.rectangle(det_img, (x1, y1),\n                    (x1 + tw, y1 - th), color, -1)\n        cv2.rectangle(mask_img, (x1, y1),\n                    (x1 + tw, y1 - th), color, -1)\n        cv2.putText(det_img, caption, (x1, y1),\n                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n\n        cv2.putText(mask_img, caption, (x1, y1),\n                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n\n    return cv2.addWeighted(mask_img, mask_alpha, det_img, 1 - mask_alpha, 0)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:23.256868Z","iopub.execute_input":"2024-05-31T02:54:23.257273Z","iopub.status.idle":"2024-05-31T02:54:23.270678Z","shell.execute_reply.started":"2024-05-31T02:54:23.257240Z","shell.execute_reply":"2024-05-31T02:54:23.269899Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def video_tracking(video_path,detector,tracker,is_save_result = False,save_dir = 'tracking_results'):\n    cap = cv2.VideoCapture(video_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    \n    if is_save_result:\n        os.makedirs(save_dir,exist_ok = True)\n        \n        fps = int(cap.get(cv2.CAP_PROP_FPS))\n        \n        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n        \n        save_result_name = 'output_video.avi'\n        save_result_path = os.path.join(save_dir,save_result_name)\n        \n        out = cv2.VideoWriter(save_result_path,fourcc,fps,(width,height))\n        \n    all_tracking_results = []\n    tracked_ids = np.array([],dtype = np.int32)\n    \n    while True:\n        ret,frame = cap.read()\n        if not ret:\n            break\n        detector_results = detector.detect(frame)\n        bboxes, scores, class_ids = detector_results\n        \n        tracker_pred = tracker.tracking(\n            origin_frame = frame,\n            bboxes = bboxes,\n            scores = scores,\n            class_ids = class_ids\n        )\n        if tracker_pred.size>0:\n            bboxes = tracker_pred[:,:4]\n            class_ids = tracker_pred[:,4].astype(int)\n            conf_scores = tracker_pred[:,5]\n            tracking_ids = tracker_pred[:,6].astype(int)\n            \n            new_ids = np.setdiff1d(tracking_ids,tracked_ids)\n            \n            tracked_ids = np.concatenate((tracked_ids,new_ids))\n            \n            result_img = draw_detection(\n                img = frame,\n                bboxes = bboxes,\n                scores = conf_scores,\n                class_ids = class_ids,\n                ids = tracking_ids\n            )\n        else:\n            result_img = frame\n        all_tracking_results.append(tracker_pred)\n        \n        if is_save_result == 1:\n            out.write(result_img)\n        \n        if 0xFF == ord('q'):\n            break\n            \n        \n    cap.release()\n    if is_save_result:\n        out.release()\n    #cv2.destroyAllWindows()\n    \n    return all_tracking_results","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:23.273946Z","iopub.execute_input":"2024-05-31T02:54:23.274293Z","iopub.status.idle":"2024-05-31T02:54:23.288320Z","shell.execute_reply.started":"2024-05-31T02:54:23.274271Z","shell.execute_reply":"2024-05-31T02:54:23.287222Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"yolo_model_path = '/kaggle/input/yolo-parameter/MOT17/best.pt'\n\ndetector = YOLOv8(yolo_model_path)\n\ntracker = DeepSORT()\n\nvideo_path = '/kaggle/input/final01/MOT17-11-DPM-raw.mp4'\nall_tracking_results = video_tracking(\n    video_path,\n    detector,\n    tracker,\n    is_save_result = True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T02:54:23.289721Z","iopub.execute_input":"2024-05-31T02:54:23.290544Z","iopub.status.idle":"2024-05-31T02:55:33.856329Z","shell.execute_reply.started":"2024-05-31T02:54:23.290511Z","shell.execute_reply":"2024-05-31T02:55:33.854648Z"},"trusted":true},"execution_count":11,"outputs":[]}]}